{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD8PtRXo_l1H"
   },
   "source": [
    "# Creating a simple indoor/outdoor weather monitoring system\n",
    "\n",
    "### Learning goals\n",
    "By the end of this lab you will learn:\n",
    "- How to setup an M5stack core2 device and connect it to Internet.\n",
    "- How to program an M5stack device using the uiFlow platform (https://flow.m5stack.com/).\n",
    "- How to insert new data into a bigQuery database.\n",
    "- How to get current weather data for a specific location using the openweather api (https://home.openweathermap.org/).\n",
    "- Creating a webapp with different endpoints using Flask and deploying it using GCloud cloud run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIZC4850_l1I"
   },
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MldJ52su_l1I"
   },
   "source": [
    "# 1. **Introduction and IOT devices:**\n",
    "Welcome to the Cloud and Advanced Analytics lab 4. In this lab, you will learn about M5stck IoT devices and sensors. You will program an M5stack device with an ENV-III sensor to build a simple weather station. Then you will push the weather data from the M5stack device to a BigQuery database in order to keep track of the historical weather data.\n",
    "\n",
    "\n",
    "### IoT devices\n",
    "In this lab you will work with the [M5stack Core2](https://docs.m5stack.com/en/core/core2) device and the [ENV-III unit](https://docs.m5stack.com/en/unit/envIII) which measures the temperature, humidity, etc.\n",
    "\n",
    "\n",
    "<!-- <img src=\"./imgs/core2_01.webp\" width=\"200\"> <img src=\"./imgs/envIII_01.webp\" width=\"200\">  -->\n",
    "\n",
    "<div class=\"row\">\n",
    "            <img src=\"https://drive.usercontent.google.com/download?id=110inQJbybfC9nBbJQj65fV0rPjKZ9tIk\" width=\"300\">\n",
    "            <img src=\"https://drive.usercontent.google.com/download?id=19a_ROkvIBvTpgARpRr7b901_dKWLW7kH\" width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NCkqWGS_l1J"
   },
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT9oQQoo_l1J"
   },
   "source": [
    "# **2. Setting up the weather sensor for measuring the indoor temperature and humidity**\n",
    "\n",
    "In this part, following the instructions mentioned in the lecture, we will follow the following steps:\n",
    "1. Connect the Core2 device to the power and connect it to the \"iot-unil\" WiFi network.\n",
    "2. Connect the ENV-III sensor to the Core2 device.\n",
    "3. Go to https://flow.m5stack.com/ and enter your device __API key__ in order to connect it to the device.\n",
    "4. Write a micropython code script that gets the temperature and humidity from the ENV-III sensor and displays it on the device's screen. Use labels with proper names to indicate which value on the screen belongs to temperature and which one belongs to humidity. The temperature and humidity values should be updated every 1 minute.\n",
    "  - Try to round the temperature and humidity values. You can do that by modifying the micropythin code in UIFlow.\n",
    "5. Program the Core2 device with your code and check the result.\n",
    "\n",
    "If everything goes in order, you should be able to see a result similar to the image below:\n",
    "\n",
    "<img src=\"https://drive.usercontent.google.com/download?id=13YAw1-6T7GeZvnXLXCLpmTNUfhiiU5GK\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULiu0rfM_l1J"
   },
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmAms42m_l1J"
   },
   "source": [
    "# 3. Creating a BigQuery database with the proper schema\n",
    "In this part we will create a BigQuery database. First we have to define the schema of this database, i.e., what will be the columns of this database and what will be the data type of each column. Then we will see how we can add a new row to a database using a SQL query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NXPah68_l1J"
   },
   "source": [
    "## 3.1 Defining a new BigQuery database\n",
    "First, we need to define a new BigQuery database. This database will be later used to insert the historical weather data in it. Follow the steps below to create this database.\n",
    "\n",
    "1. In your Google Cloud console, go to the BigQuery interface.\n",
    "2. From the menu on the left select BigQuery Studio.\n",
    "\n",
    "<img src=\"https://drive.usercontent.google.com/download?id=1EU4SxFTcuZRtevbF7N7VX9619EwrsiNi\" width=\"300\">\n",
    "\n",
    "3. From the pannel on the left, click on the three dots next to your project name and select create dataset. This will create a new dataset in BigQuery.\n",
    "\n",
    "<img src=\"https://drive.usercontent.google.com/download?id=1OGCVf1pbpFYEkN76XEC9Kj7_RRKgW3y2\" width=\"300\">\n",
    "\n",
    "4. Assign a proper name to the dataset (e.g. Lab4_IoT_datasets) and select the region for the dataset.\n",
    "\n",
    "<img src=\"https://drive.usercontent.google.com/download?id=1dYmV2NfikHufCPOUaZEYmKPVcPzXBH_8\" width=\"300\">\n",
    "\n",
    "5. Create a new table in the new dataset. You can call it: **weather-records**\n",
    "\n",
    "<img src=\"https://drive.usercontent.google.com/download?id=19kaG5orQd_JDjg_gPe4VW3LtPrBNKQUE\" width=\"300\">\n",
    "\n",
    "6. We will create this table from an \"Empty Table\". Also we need to define the schema of this table. Define the schema according to the following image.\n",
    "\n",
    "<img src=\"https://drive.usercontent.google.com/download?id=1GcuRVOHXjWMMbKFCjwZcfrOWs4eSIeJo\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISaOacs3_l1K"
   },
   "source": [
    "## 3.2 Test the BigQuery database we just created (authentification Google Colab)\n",
    "Now let's query the database we just created. The result of the query is expected to be an empty table"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XKazZvFZ_l1K",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "91304aab-309a-4556-c35e-eaec856339b8",
    "ExecuteTime": {
     "end_time": "2025-03-13T16:42:35.646273Z",
     "start_time": "2025-03-13T16:42:35.637151Z"
    }
   },
   "source": [
    "# import the required packages in this walkthrough\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Google Collab\n",
    "print(\"Authenticated\")\n",
    "\n",
    "# If you want to use your local jupyter notebook:\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"assignement1-aac-1b71b1a4122a.json\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "smi0ghfz_l1K",
    "ExecuteTime": {
     "end_time": "2025-03-13T16:42:39.731683Z",
     "start_time": "2025-03-13T16:42:39.707960Z"
    }
   },
   "source": [
    "# Define the BigQuery client\n",
    "client = bigquery.Client(project=\"assignement1-aac\") # PROJECT_ID"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YG0GSGKA_l1L",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "outputId": "86aa85a9-bae8-4196-851e-fe3fc65af29e",
    "ExecuteTime": {
     "end_time": "2025-03-13T16:42:41.627236Z",
     "start_time": "2025-03-13T16:42:41.011631Z"
    }
   },
   "source": [
    "q = \"\"\"\n",
    "SELECT * FROM `assignement1-aac.Lab4_IoT_datasets.weather_records`\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(q)\n",
    "df = query_job.to_dataframe()\n",
    "df"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanguy\\PycharmProjects\\TestIoT\\.venv\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1900: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         date      time  indoor_temp  indoor_humidity  outdoor_temp  \\\n",
       "0  2025-03-12  16:02:23         23.0             65.0           0.0   \n",
       "\n",
       "   outdoor_humidity outdoor_weather  \n",
       "0               0.0           Sunny  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>indoor_temp</th>\n",
       "      <th>indoor_humidity</th>\n",
       "      <th>outdoor_temp</th>\n",
       "      <th>outdoor_humidity</th>\n",
       "      <th>outdoor_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>16:02:23</td>\n",
       "      <td>23.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zud67viy_l1L"
   },
   "source": [
    "## 3.3 Insert new rows in the BigQuery table\n",
    "For this application, we need to insert new rows in the BigQuery table in order to be able to keep track of the historical data. To do this we can use the SQL `INSERT` statement. See the documentation to know more about the syntax of this statement: https://cloud.google.com/bigquery/docs/reference/standard-sql/dml-syntax#insert_statement\n",
    "\n",
    "Note that if you do not specify any values for some of the columns, those columns will get a NULL value. Follow the following examples to better understand how does the `INSERT` statement works."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EcW59R1c_l1L",
    "ExecuteTime": {
     "end_time": "2025-03-13T16:42:53.107780Z",
     "start_time": "2025-03-13T16:42:52.838744Z"
    }
   },
   "source": [
    "# Insert some random values!\n",
    "q = f\"\"\"\n",
    "INSERT INTO `assignement1-aac.Lab4_IoT_datasets.weather_records`\n",
    "(date, time, indoor_temp, indoor_humidity, outdoor_temp, outdoor_humidity, outdoor_weather)\n",
    "VALUES('2025-03-12', '16:02:23', 23, 65, 0, 0, 'Sunny')\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(q)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FVI9qe0A_l1L",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "outputId": "9e0337ff-f8d6-4a24-b7cb-d41fe12cb009",
    "ExecuteTime": {
     "end_time": "2025-03-13T16:42:55.205175Z",
     "start_time": "2025-03-13T16:42:54.734801Z"
    }
   },
   "source": [
    "# Now we can query the database again and see the new row added to it!\n",
    "q = f\"\"\"\n",
    "SELECT * FROM `assignement1-aac.Lab4_IoT_datasets.weather_records`\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(q)\n",
    "df = query_job.to_dataframe()\n",
    "df"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanguy\\PycharmProjects\\TestIoT\\.venv\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1900: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         date      time  indoor_temp  indoor_humidity  outdoor_temp  \\\n",
       "0  2025-03-12  16:02:23         23.0             65.0           0.0   \n",
       "1  2025-03-12  16:02:23         23.0             65.0           0.0   \n",
       "\n",
       "   outdoor_humidity outdoor_weather  \n",
       "0               0.0           Sunny  \n",
       "1               0.0           Sunny  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>indoor_temp</th>\n",
       "      <th>indoor_humidity</th>\n",
       "      <th>outdoor_temp</th>\n",
       "      <th>outdoor_humidity</th>\n",
       "      <th>outdoor_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>16:02:23</td>\n",
       "      <td>23.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-12</td>\n",
       "      <td>16:02:23</td>\n",
       "      <td>23.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmyH05h8_l1L"
   },
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRs6k-es_l1L"
   },
   "source": [
    "# 4. Creating a web service that receives data from the IoT device\n",
    "Because of the limitations of the micropython, we are not able to install Google Cloud packages on the device and therefore we are not able to directly query the BigQuery table from the device. Therefore, we need to create a web service accesible via the Internet, so that we can send the data from the device to that web service. The job of the web service is to receive the data from the M5stack device and insert it in the BigQuery table.\n",
    "\n",
    "The script `main.py` in the lab's folder will create a simple Flask application that can recieve data from the IoT device and insert it into your BigQuery database. pay attention to the following remarks about this flask app:\n",
    "\n",
    "- A flask app in general can have multiple endpoint. In this part, we want to use the `/send-to-bigquery` endpoint. This endpoint will accept a post request from the IoT device that contains the indoor temperature values inside a json file. Then it builds a SQL query based on these values and sends this query to the BigQuery database. Please take a moment and look carefully how the SQL query is being made.\n",
    "- It is important to make sure that only you, as the owner of the database, can call this endpoint and insert new rows inside the database! To do so, we need to make the calls to this endpoint __authenticated__. One way to do that is to set up a password which will be checked on the flask server. To avoid sending the password from the IoT device in plain text, we need to hash this password first and send it to the flask server. In the flask server, the correct hash string is already stored and each time a post request is made the received hash string (from the IoT device) will be checked against the stored hash string. In the `m5stack.py` script, see how we have set-up a password and converted it to a hash string. In the `main.py` script (flask app), see how the correctness of the hash string is checked for each post request. To know more about hash functions, check the [wikipedia page](https://en.wikipedia.org/wiki/Hash_function).\n",
    "- In the `m5stack.py` script select a password for yourself (the `passwd` variable).\n",
    "- In the `m5stack.py` script, observe that we send data to the flask app every 5 minutes.\n",
    "- You need to store the hash of your password in the flask server. You can use the code cell below to hash your password. Copy the result to the `main.py` file (`YOUR_HASH_PASSWD` variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "8yHkCY2j_l1L",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "outputId": "cd478ed3-148b-4dd1-a2c0-24dfb3f6a16c"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'cf0461154c91c85275cbf98074832dcf2ad59f9a9f2ab11f8189e4cea6fdd323'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "h = hashlib.sha256(b\"patate\") # change this to a password of choice!\n",
    "h.hexdigest() # this is the hashed password: YOUR_HASH_PASSWD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXmTZoYc_l1M"
   },
   "source": [
    "To test the endpoint locally on your computer, you can dowonload the `main.py` file and run it on your computer.\n",
    "\n",
    "In your terminal run `python main.py`.\n",
    "\n",
    "You can use the following cell to test your endpoint locally."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5LPTX5Rt_l1M",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1dad18e0-49d6-40ed-f701-d8f3077f4b49",
    "ExecuteTime": {
     "end_time": "2025-03-13T16:46:52.045559Z",
     "start_time": "2025-03-13T16:46:51.895764Z"
    }
   },
   "source": [
    "data = {\n",
    "    \"passwd\": \"cf0461154c91c85275cbf98074832dcf2ad59f9a9f2ab11f8189e4cea6fdd323\",\n",
    "    \"values\": {\n",
    "        \"date\": \"2025-03-13\", # example of the correct format: '2025-03-13'\n",
    "        \"time\": \"16:30:00\", # example of the correct format: '16:30:00'\n",
    "        \"indoor_temp\": 23, # random values for the indoor temperature and humidity\n",
    "        \"indoor_humidity\": 67\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(\"http://127.0.0.1:8080/send-to-bigquery\", json=data)\n",
    "\n",
    "print(response.status_code, response.text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 {\n",
      "  \"data\": {\n",
      "    \"date\": \"2025-03-13\",\n",
      "    \"indoor_humidity\": 67,\n",
      "    \"indoor_temp\": 23,\n",
      "    \"time\": \"16:30:00\"\n",
      "  },\n",
      "  \"status\": \"sucess\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjlgHNozLgKz"
   },
   "source": [
    "If the above cells do not work for you, you can try sending a request directly from your git bash terminal Use the send_requests.sh file to do so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYBpK0r__l1M"
   },
   "source": [
    "If you have replaced the place holders with the correct string/values, then after running the above cell you should see the new row being added to your db. If you are running this locally, make sure that the key you are using has the correct the right credentials to write in BigQuery! (IAM & Admin < IAM < select the key you are using < BigQuery Admin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "EPvhDbgG_l1M",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "outputId": "6065086f-b47d-4331-facc-dfd5ce527ca0"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "BadRequest",
     "evalue": "400 Invalid project ID 'PROJECT_ID'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.; reason: invalid, location: PROJECT_ID.DATABASE_ID.weather_records, message: Invalid project ID 'PROJECT_ID'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.\n\nLocation: US\nJob ID: 7c085550-edb6-4bb7-8843-2622e2e8a027\n",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mBadRequest\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-29-9f7f0430791f>\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mquery_job\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquery\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mq\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mquery_job\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_dataframe\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/bigquery/job/query.py\u001B[0m in \u001B[0;36mto_dataframe\u001B[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001B[0m\n\u001B[1;32m   2055\u001B[0m                 \u001B[0;34m:\u001B[0m\u001B[0mmod\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mshapely\u001B[0m\u001B[0;31m`\u001B[0m \u001B[0mlibrary\u001B[0m \u001B[0mcannot\u001B[0m \u001B[0mbe\u001B[0m \u001B[0mimported\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2056\u001B[0m         \"\"\"\n\u001B[0;32m-> 2057\u001B[0;31m         \u001B[0mquery_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwait_for_query\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprogress_bar_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_results\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax_results\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2058\u001B[0m         return query_result.to_dataframe(\n\u001B[1;32m   2059\u001B[0m             \u001B[0mbqstorage_client\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbqstorage_client\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/bigquery/_tqdm_helpers.py\u001B[0m in \u001B[0;36mwait_for_query\u001B[0;34m(query_job, progress_bar_type, max_results)\u001B[0m\n\u001B[1;32m    105\u001B[0m     )\n\u001B[1;32m    106\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mprogress_bar\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 107\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mquery_job\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_results\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax_results\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    108\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    109\u001B[0m     \u001B[0mi\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/bigquery/job/query.py\u001B[0m in \u001B[0;36mresult\u001B[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001B[0m\n\u001B[1;32m   1679\u001B[0m                 \u001B[0;31m# Since is_job_done() calls jobs.getQueryResults, which is a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1680\u001B[0m                 \u001B[0;31m# long-running API, don't delay the next request at all.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1681\u001B[0;31m                 \u001B[0;32mwhile\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_job_done\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1682\u001B[0m                     \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1683\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001B[0m in \u001B[0;36mretry_wrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    291\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_initial\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maximum\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmultiplier\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_multiplier\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    292\u001B[0m             )\n\u001B[0;32m--> 293\u001B[0;31m             return retry_target(\n\u001B[0m\u001B[1;32m    294\u001B[0m                 \u001B[0mtarget\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    295\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_predicate\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001B[0m in \u001B[0;36mretry_target\u001B[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m             \u001B[0;31m# defer to shared logic for handling errors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 153\u001B[0;31m             _retry_error_helper(\n\u001B[0m\u001B[1;32m    154\u001B[0m                 \u001B[0mexc\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m                 \u001B[0mdeadline\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_base.py\u001B[0m in \u001B[0;36m_retry_error_helper\u001B[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001B[0m\n\u001B[1;32m    210\u001B[0m             \u001B[0moriginal_timeout\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    211\u001B[0m         )\n\u001B[0;32m--> 212\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mfinal_exc\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msource_exc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    213\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mon_error_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    214\u001B[0m         \u001B[0mon_error_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001B[0m in \u001B[0;36mretry_target\u001B[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[0m\n\u001B[1;32m    142\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0msleep\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msleep_generator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 144\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    145\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0minspect\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misawaitable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    146\u001B[0m                 \u001B[0mwarnings\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwarn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_ASYNC_RETRY_WARNING\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/bigquery/job/query.py\u001B[0m in \u001B[0;36mis_job_done\u001B[0;34m()\u001B[0m\n\u001B[1;32m   1628\u001B[0m                         \u001B[0;31m# `job_retry` predicate.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1629\u001B[0m                         \u001B[0mrestart_query_job\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1630\u001B[0;31m                         \u001B[0;32mraise\u001B[0m \u001B[0mjob_failed_exception\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1631\u001B[0m                     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1632\u001B[0m                         \u001B[0;31m# Make sure that the _query_results are cached so we\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mBadRequest\u001B[0m: 400 Invalid project ID 'PROJECT_ID'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.; reason: invalid, location: PROJECT_ID.DATABASE_ID.weather_records, message: Invalid project ID 'PROJECT_ID'. Project IDs must contain 6-63 lowercase letters, digits, or dashes. Some project IDs also include domain name separated by a colon. IDs must start with a letter and may not end with a dash.\n\nLocation: US\nJob ID: 7c085550-edb6-4bb7-8843-2622e2e8a027\n"
     ]
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT * FROM `PROJECT_ID.DATABASE_ID.weather_records`\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(q)\n",
    "df = query_job.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ8DG104_l1M"
   },
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQbopvgS_l1M"
   },
   "source": [
    "# 5. Deploying the Flask app in Google Cloud\n",
    "\n",
    "To deploy the Flask app in the Gcloud Cloud Run, you have to follow the following steps:\n",
    "1. Download the following files from the course repository and push them to your private repository.\n",
    "    - `main.py`\n",
    "    - `requirements.txt`\n",
    "    - `Dockerfile`\n",
    "2. Navigate to Cloud Run in your Google Cloud console and open a cloud shell terminal.\n",
    "3. In the terminal navigate to the directory corresponding to your git repository and do `git pull`\n",
    "4. Follow the instructions in lab 1 to build the docker image and push it to the container registry.\n",
    "5. Follow the instrucitons in lab 1 to deploy the created image in the container registry to Cloud Run.\n",
    "\n",
    "After completing the above steps successfully, you would get a URL for Flask web service. Try to insert some artificial data to the BigQuery db using the URL. You can use the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y27i4r42_l1M"
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"passwd\": \"YOUR_HASH_PASSWD\",\n",
    "    \"values\": {\n",
    "        \"date\": \"<some_random_date>\", # example of the correct format: '2025-03-13'\n",
    "        \"time\": \"<some_random_time>\", # example of the correct format: '16:30:00'\n",
    "        \"indoor_temp\": 23, # random values for the indoor temperature and humidity\n",
    "        \"indoor_humidity\": 67\n",
    "    }\n",
    "}\n",
    "\n",
    "requests.post(\"<URL_FROM_CLOUDRUN>/send-to-bigquery\", json=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_j7V4Wu_l1N"
   },
   "source": [
    "Check if the data has been inserted correctly to the db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5JlWY1RA_l1N"
   },
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT * FROM `cloud-course-450015.Lab4_IoT_datasets.weather-records`\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(q)\n",
    "df = query_job.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZM6MKPM_l1N"
   },
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiYoiraC_l1N"
   },
   "source": [
    "# 6. Updating the `m5stack.py` with the URL of the deployed web service\n",
    "\n",
    "Finally, you have to update the `m5stack.py` file with the URL of the web service you just deployed. After doing so, program the Core2 device with the new script. In the first iteration of the loop, the values of the ENV-III measurements will be sent to the server. So you sould be able to see the values added to the db almost immediately (You can check it by running a query!). After that, you should be able to see new values added to the server every 5 minutes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XEtTI9U_l1N"
   },
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I65xantO_l1N"
   },
   "source": [
    "# 7. Your Turn\n",
    "\n",
    "1. Right now we are only inserting the measurements of the ENV-III sensor, temperature and humidity, to the db every 5 minutes. However, it is impossible to keep track of the historical data without keeping track of the actual time they were recorded. Therefore, we need to also send the time of the measurements from the Core2 device to the server. Try to do that! (Hint: check the `rtctime` package: https://docs.m5stack.com/en/uiflow/blockly/hardwares/rtc)\n",
    "\n",
    "2. In the Flask server, augment the `/send-to-bigquery` endpoint such that for each post request it gets the weather information from the openweather api and insert the corresponding values in the `outdoor_weather`, `outdoor_humidity`, and `outdoor_weather` columns of the db. For the `outdoor_weather` column, use the value corresponding to the key `description` from the json file you get from the openweather api.\n",
    "\n",
    "3. Create a new endpoint `/get_outdoor_weather` in the Flask app that accepts post requests and sends back the outdoor humidity and temperature values it gets from the latest entry in the db. In order to make sure that only you can read the records in your database, verify the password in this post request. Try to use this endpoint in the Core2 device so that you can show the outdoor weather info on the device.\n",
    "    3.1. __bonus__: Can you also show the current date and time on the device?\n",
    "    \n",
    "\n",
    "After doing the 2nd and 3rd exercises, you can expect ot have this information on your Core2 device:\n",
    "\n",
    "<img src=\"https://drive.usercontent.google.com/download?id=1fFtimdTCoP0GsL561hISafFbFe9fFeaP\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBv7snTe_l1N"
   },
   "outputs": [],
   "source": [
    "# Help to call the openweather api\n",
    "\n",
    "API_key = \"YOUR_API_KEY\"\n",
    "\n",
    "city = \"Lausanne\"\n",
    "\n",
    "url = f'http://api.openweathermap.org/data/2.5/weather?q={city}&appid={API_key}&units=metric'\n",
    "\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PBSavhH_l1O"
   },
   "outputs": [],
   "source": [
    "temp = round(response.json()['main']['temp'])\n",
    "humidity = round(response.json()['main']['humidity'])\n",
    "weather = response.json()['weather'][0]['description']\n",
    "\n",
    "print(f\"temp: {temp}, humidity: {humidity}, weather: {weather}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
